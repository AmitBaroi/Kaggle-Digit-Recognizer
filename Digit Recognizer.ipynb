{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Digit Recognizer\nThis is a simple image classification challenge using the famous [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). Lets see if we can train a classifier that can accurately distinguish handwritten digits. For my implementation, instead of using a traditional machine learning classifier like Support Vector Machine or Random Forest, I will be using a [Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network), as they are by far the best choice for image data.\n\n<img src=\"images/MnistExamples.png\">\n\n### Goal\nThe goal is to take an image of a handwritten single digit, and determine what that digit is. For every image in the test set, we want to predict the correct label.\n\n### Metric\nThis competition is evaluated on the categorization accuracy of our predictions (the percentage of images labeled correct)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\nimport tensorflow as tf # Deep Learning Yo!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading **taining** and **testing** data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperating features (images : X) and labels (correct digit labels: y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train[\"label\"]\nX_train = train.drop(labels=[\"label\"], axis=1); del train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data exploration"},{"metadata":{},"cell_type":"markdown","source":"Checking the count of each label"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nsns.countplot(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are more or less similar number of images for each digit. So its less likely that our classifier will get biased due to representation error (eg: suppose the digit 5 being predicted most of the time because there are a larger number of images of 5s in our dataset compared to other numbers)."},{"metadata":{},"cell_type":"markdown","source":"## 2. Data preparation"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Reshaping images\nThe images are currently flattened: 28x28 grayscale images flattened = 784 pixels. This is so that it is easier to pass into traditional Machine Learning classifiers such as SVCs or Random Forest classifiers. However, for image data Convolutional Neural Networks (CNNs) are currently the best choice. Therefore, we will reshape the images into their original dimensions: 28x28x1 (1 channel)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.values.reshape(-1, 28, 28, 1) # Training images\ntest = test.values.reshape(-1, 28, 28, 1)       # Test set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking a few random images:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\nfor i in range(5):\n    index = np.random.randint(0, len(X_train)-1)\n    axes[i].imshow(X_train[index][:, :, 0], cmap='binary')\n    print(y_train[index], end=\"\\t\\t\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Normalization\nWe will normalize the images to reduce the impact of alpha differences. Normalization also helps models converge faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking impact of normalization on images:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(8, 8))\nfor i in range(5):\n    index = np.random.randint(0, len(X_train)-1)\n    axes[i].imshow(X_train[index][:, :, 0], cmap='binary')\n    print(y_train[index], end=\"\\t\\t\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalization doesn't fundamentally change our image. It only shifts the pixel values so that they have mean of 0 and standard deviation of 1."},{"metadata":{},"cell_type":"markdown","source":"### 2.3 One-hot encoding for labels\nOne-hot encoding is a process by which categorical variables like $[cat, dog]$ or $[0, 1, 2,...,9]$ are converted into one-hot vectors. \n\nIn this case, we have 10 classes - the numbers 0-9. Now, suppose a random image label $ y_i = 5 $, one-hot encoding will represent this as a one-hot vector $[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]$, similarly if $ y_i = 0 $, it will be represented as $[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]$."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder(categories='auto')\n\nY_train = enc.fit_transform(y_train.to_numpy().reshape(-1, 1)).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Original label, $ y_0 $:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_train[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After one-hot encoding, $Y_0$:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image, $X_0$:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[0][:, :, 0], cmap='binary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the labels are now represented differently. Instead of a single integer, it is now represented by a one-hot vector."},{"metadata":{},"cell_type":"markdown","source":"### 2.4 Seperating training data into training and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train), len(X_val), len(Y_train), len(Y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Modeling\nFor implementing Convolutional Networks, we will use Tensorflow's official high level API - Keras."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential() # Instance of the Sequential model class\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1))) # Input\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu')) # CONV hidden layer 1\nmodel.add(MaxPool2D(pool_size=(2,2))) # Pooling 1\nmodel.add(Dropout(0.25)) # Regularization\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')) # CONV hidden layer 2\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')) # CONV hidden layer 3\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2))) # Pooling 2\nmodel.add(Dropout(0.25)) # Regularization\n\nmodel.add(Flatten()) # 2D -> 1D\nmodel.add(Dense(256, activation=\"relu\")) # FC (fully connected) hidden layer\nmodel.add(Dropout(0.5)) # Regularization\n\nmodel.add(Dense(10, activation=\"softmax\")) # Output prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile model\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, Y_train, batch_size=86, epochs=3, validation_data=(X_val, Y_val), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.6 (tf_env)","language":"python","name":"tf_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":1}